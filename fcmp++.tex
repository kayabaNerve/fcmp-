\documentclass[]{article}

\usepackage{amsmath}

\title{FCMP++}
\author{Luke "Kayaba" Parker}

\begin{document}

\maketitle

\begin{abstract}
	
	FCMP++, shortened from FCMP+SA+L, short for Full-Chain Membership Proofs + Spend Authorization + Linkability, are an accomplishment of full-set privacy over the existing RingCT protocol used within Monero. This document serves as a specification and implementation reference.

\end{abstract}

\section{Background}

\newcommand{\hashtopoint}{\mathsf{HashToPoint}}

Monero is currently planning to deploy the Seraphis upgrade, most notable for its definition as a composition which distinguishes membership from spend authorization. With that, we are allowed much more efficient membership proofs (enabling full-set privacy). RingCT, which fails to so distinguish, was considered infeasible for full-set privacy for that reason and due to how its linking tags are defined.

With Seraphis, outputs are defined as $k_0 \cdot G_0 + k_1 \cdot G_1 + k_2 \cdot G_2$ with the linking tag defined as $(k_2 / k_1) \cdot J$. This allows $k_0$ to be re-randomized without malleating the linking tag.

With a new definition of linking tags, it forces creation of a new anonymity set (with explicit migration) to prevent double-spending of already spent outputs (which would now be given a new linking tag if 'imported' by simply adding a $1 G_2$ term).

With RingCT, outputs are defined as $O = x \cdot G$ with the linking tag defined as $x \cdot \hashtopoint(O)$. To re-randomize $x$ would be to malleate the linking tag.

\section{New Output Key Definition}

Since we cannot re-define the linking tags, we re-define the output key. We introduce a new generator, $T$, re-define output keys as $O = x \cdot G + y \cdot T$ (where $y = 0$ for all existing outputs), and preserve the linking tag definition of $x \cdot \hashtopoint(O)$. This causes all existing outputs to maintain their linking tags while giving us a term to re-randomize.

\newpage

\section{Proof Separation}

Seraphis defines four distinct proofs.

\begin{enumerate}
	\item
	Membership Proof.
	
	The tuple of the commitment being spent by this input and the output key associated with it is a member of the set of outputs within this blockchain.

	\item "Ownership and Unspentness" (Spend Authorization and Linkability).
	
	The transaction created is authorized by the possessor of the private keys for the output key. The commitment spent has not been prior spent.
	
	\item
	Balance Proof.
	
	This transaction does not create outputs worth more than the inputs spent.
	
	\item
	Range Proof.
	
	The outputs do not overflow the order of the elliptic curve in order to cheat the balance proof.
\end{enumerate}

We appreciate and maintain these four definitions. We focus on the first two, currently jointly satisfied by CLSAG. We define one proof for the former and compose it with a new proof for the latter.

\subsection{New Membership Proof}

$\mathsf{OutputSet}$ is defined as a set of $(O, I, C)$ tuples (where $O$ is the output key, $I = \hashtopoint(O)$, and $C$ the amount commitment). 

For an output tuple $(O, I, C)$, the prover samples scalars $r_o, r_i, r_j, r_c$. They then prove knowledge of those scalars and:

$\tilde{O} = O + r_o \cdot T$

$\tilde{I} = I + r_i \cdot U$

$R = r_i \cdot V + r_j \cdot T$

$\tilde{C} = C + r_c \cdot G$

$(O, I, C) \in \mathsf{OutputSet}$

while only publishing $\tilde{O}, \tilde{I}, \tilde{C}, R$ (the 'input tuple').

This does not require knowledge of $x, y$ (nor the opening of the Pedersen commitment $C$) and accordingly can be produced by any party trusted with sender privacy. Exactly how this membership proof occurs is left as a black box to the rest of these designs, yet further specified later.

\newpage

\subsection{New Spend Authorization and Linkability Proof}

For an input tuple $\tilde{O}, \tilde{I}, \tilde{C}, R$, and linking tag $L$, prove knowledge of $x, y', r_i$ such that $\tilde{O} = x \cdot G + y' \cdot T, R = r_i \cdot V + r_j \cdot T, \tilde{I} = I + r_i \cdot U$, and $L = x \cdot I$ (while binding to the transaction hash). To be explicit, $y' = y + r_o$.

We instantiate this literally with a Bulletproof+ (https://eprint.iacr.org/2020/735) composed with a Generalized Schnorr Protocol (https://eprint.iacr.org/2009/050).

We start by inlining the math for the Bulletproof+ Weighted-Inner Product proof (in its single round form with its $y = 1$, as that's all we need).

\begin{enumerate}
	\item
	Prover samples $r_p, \alpha, \beta, \mu, \delta$ and publishes:
	\begin{itemize}
		\item
		$P = x \cdot G + r_i \cdot V + (x * r_i) \cdot U + r_p \cdot T$
		
		This is the $P$ from the statement of Bulletproof+'s weighted-inner-product proof for $\boldsymbol{g} = [G], \boldsymbol{h} = [V], g = U, h = T$ (in its own notation).
		\item
		$A = \alpha \cdot G + \beta \cdot V + ((\alpha * y) + (\beta * x)) \cdot U + \delta \cdot T$
		\item
		$B = (\alpha * \beta) \cdot U + \mu \cdot T$
	\end{itemize}
	\item
	Verifier sends challenges $e$.
	\item
	Prover publishes:
	\begin{itemize}
		\item
		$s_\alpha = \alpha + e \cdot x$	
		\item
		$s_\beta = \beta + e \cdot r_i$
		\item
		$s_\delta = \mu + \delta * e + r_p * (e * e)$
	\end{itemize}
	\item
	Verifier checks:
	\begin{itemize}
		\item
		$(e * e) \cdot P + e \cdot A + B = (s_\alpha * e) \cdot G + (s_\beta * e) \cdot V + (s_\alpha * s_\beta) \cdot U + s_\delta \cdot T$
	\end{itemize}
\end{enumerate}

We now have $P = x \cdot G + r_i \cdot V + (x * r_i) \cdot U + r_p \cdot T$ for some $x, r_i, r_p$. We set $P' = P - \tilde{O} - R$. For $P, \tilde{O}$, the only $G$ term is for $x$. If the $x$s are consistent, $P'$ will not have a $G$ term. For $P, R$, the only $V$ term is for $r_i$. If the $r_i$s are consistent, $P'$ will not have a $V$ term. For an honest prover, this leaves $P' = (x * r_i) \cdot U + (r_p - y' - r_j) \cdot T$.

We now compose this with a Generalized Schnorr Protocol to:
\begin{itemize}
	\item Open $P'$ over $U, T$, proving $x$ and $r_i$ were consistent.
	\item Prove the linking tag is well-formed.
\end{itemize}

\begin{enumerate}
	\item
	Prover samples $r_x, r_y, r_z, r_{r_p}$ and publishes:
	\begin{itemize}
		\item
		$R_O = r_x \cdot G + r_y \cdot T$
		
		This is a commitment to the nonces we use when showing we know an opening of $\tilde{O}$.
		\item
		$R_P = r_z \cdot U + r_{r_p} \cdot T$
		
		This is a commitment to the nonces we use when showing we know an opening of $P'$.
		\item
		$R_L = r_x \cdot \tilde{I} + r_z \cdot -U$		

		This is a commitment to the nonces we use when showing we know a consistent opening of $L$.
	\end{itemize}
	\item
	Verifier sends challenges $c$.
	\item
	Prover publishes:
	\begin{itemize}
		\item
		$s_x = r_x + c \cdot x$	
		\item
		$s_y = r_y + c \cdot y'$
		\item
		$s_z = r_z + c \cdot (x * r_i)$
		
		This implicitly makes $z$, never explicitly defined, $x * r_i$.
		\item
		$s_{r_p} = r_{r_p} + c \cdot (r_p - y' - r_j)$
		
		$r_p - y' - r_j$ is the coefficient for the $T$ term of $P'$.
	\end{itemize}
	\item
	Verifier checks:
	\begin{itemize}
		\item
		$R_O + c \cdot \tilde{O} == s_x \cdot G + s_y \cdot T$
		
		This verifies the opening of $\tilde{O}$.
		\item
		$R_P + c \cdot P' == s_z \cdot U + s_{r_p} \cdot T$
		
		This verifies the opening of $P'$ over $U, T$.
		\item
		$R_L + c \cdot L == s_x \cdot \tilde{I} + s_z \cdot -U$
		
		This verifies the opening of $L$ as $x \cdot \tilde{I} + (x * r_i) \cdot -U$. Since $x \cdot \tilde{I}$ is $x \cdot I + (x * r_i) \cdot U$, this will remove the additional term (proved correct and consistent with the Bulletproof+), leaving $x \cdot I$ (the intended linking tag).
	\end{itemize}
\end{enumerate}

In the future, we should review specialized proofs. It would not be surprising if $s_x$ can be replaced for just $s_\alpha$, along with a few other similar tweaks.

\newpage

\section{The Literal Membership Proof}

With the proofs separated, and spend authorization satisfied, we still need membership. We prove membership over the entire output set using an arithmetic circuit verifying a Merkle tree proof. Since Merkle tree proofs have O(log n) time complexity, a proof with O(n) complexity still achieves a O(log n) solution to the problem statement.

This makes the requirement a sufficiently performant, zero-knowledge proof for the satisfaction of an arithmetic circuit, yet not explicitly a SNARK (which would mandate sublinear time complexity).

\subsection{Arithmetic Circuit Proof}

Bulletproofs are a trustless proof already used within Monero, which can be used to prove arithmetic circuit proofs are satisfied. We solely need a hash function for the Merkle tree, the most efficient being a Pedersen hash.

A Pedersen hash is a collision-resistant hash where for each word hashed, an additional term is added to a Pedersen Vector Commitment. Finding a collision implies finding the discrete log relationship of the generators used.

Creating Pedersen hashes in-circuit would be too expensive. Bulletproofs offer arithmetic over the scalar field of the curve, yet Pedersen hashes produce an output over the field the curve is defined over. Accordingly, it'd require non-native arithmetic. If we instead use an elliptic curve whose scalar field is the field of the curve we're performing the hash with (an 'embedded' or 'towered' curve), we'd have a cost of 256 in-circuit multiplications per word hashed (for a 256-bit elliptic curve).

We instead use Generalized Bulletproofs, a proposed modification to Bulletproofs currently undergoing work to obtain security proofs. Generalized Bulletproofs can be used to output Pedersen hashes at effectively no additional cost, although it cannot operate over its hashes (and we do need to operate over a series of hashes, due to discussing a Merkle tree). We solve this by operating over output hashes with a new Generalized Bulletproof, this one on a curve whose scalar field is the prior curve's field. This continues for each layer of the Merkle tree, and is most efficiently realizable with a curve cycle (a curve whose scalar field is the field of a curve whose scalar field is the field for the original curve). With a curve cycle, one can alternate between the two curves (and two proofs) without needing additional curves/proofs per layer.

The ability to produce Pedersen hashes also enables forming challenges off partial transcripts of the witness. By defining a Pedersen hash of the first $n$ variables within the circuit, we can hash that outside of the circuit with a traditional hash function to obtain a challenge usable for the rest of the circuit. This allows interactive proofs within the circuit (due to the Fiat-Shamir transform), and with it, more efficient gadgets.

For the concept of Generalized Bulletproofs, and opening a Merkle tree using Pedersen hashes with a pair of Bulletproofs over a curve cycle in such an efficient manner, please thank the authors of Curve Trees, https://eprint.iacr.org/2022/756. This proposal applies their work to RingCT and performs further optimizations via the usage of divisors, yet does not claim to be novel.

\subsubsection{Alternatives}

Bulletproofs and Bulletproofs+ both define commitments to the witness ($A_I, A$ respectively). These commitments are Pedersen hashes of the entire witness. If these commitments are moved into the statement, we can independently use Bulletproofs+ zk-WIP argument (or ideally a tailored version of it, as we don't need the inner-product functionality) to prove subsets of the commitment are validly formed. By defining the subsets as the variables we want hashed for the Merkle tree, we achieve Pedersen hashing with non-negligible overhead (~3x in verification time, with bandwidth scaling near-linear to the amount of hashes performed).

Distinctly, we could discuss modifying the Bulletproof(+) statement to explicitly support such subsets, presumably via an additional challenge. This would have minimal overhead (an amount comparable to Generalized Bulletproofs if accomplished), be less expressive than Generalized Bulletproofs, yet largely as performant in both bandwidth and verification time.

Neither of these ideas are put forth as guaranteed fallbacks at this time. Solely likely sufficiently performant alternatives if there is an issue with proving Generalized Bulletproofs secure which we can discuss researching.

\subsection{Towering Curve Cycle}

Since we're performing full-chain membership proofs over Monero's RingCT, and Monero's RingCT uses Ed25519, we need a curve cycle involving Ed25519. Unfortunately, a curve cycle with Ed25519 is impossible for non-trivial curves. This is due to Ed25519 having a cofactor of 8. Instead of forming a curve cycle with Ed25519, we find a prime-order curve whose scalar field is Ed25519's field, and then form a curve cycle with that. This is referred to as a towering curve cycle, due to it being a curve cycle where one curve towers (stands over, not forming a cycle with) Ed25519.

tevador proposed Helios and Selene for an efficient towering curve cycle, documenting the deterministic method used to find them and their security. Please see https://gist.github.com/tevador/4524c2092178df08996487d4e272b096.

\subsection{Gadgets}

We define an arithmetic circuit with two parts to its statement.

\begin{itemize}
	\item
	$a_l * a_r = a_o$
	
	For vectors $a_l, a_r, a_o$, $a_o$ is the vector multiplication of $a_l, a_r$.
	\item
	$W_l * a_l + W_r * a_r + W_o * a_o + W_v * V = c$
	
	For matrices $W_l, W_r, W_o, W_v$, this constraint is run for each column (where all have the same amount of columns). Defining $W_l, W_r, W_o, W_v$ as the column of $W_l, W_r, W_o, W_v$ currently relevant, $W_l * a_l, W_r * a_r, W_o * a_o$ is the inner product of the column and the vector.
	
	For $W_v, V$, this is defined by Bulletproofs(+) to be the Pedersen commitments accessible within the circuit and associated weights. We define $V$ as the Pedersen vector commitments, where instead of the length of a column of $W_v$ being the amount of Pedersen commitments, the length of a column is the amount of variables within the Pedersen vector commitment in question. The depth refers to which Pedersen vector commitment is currently being constrained.
	
	While Generalized Bulletproofs still supports Pedersen commitments, we drop the functionality from consideration and don't bother notating it due to lack of use.
	
	$c$ is a row of constants of length equal to the amount of columns in $W_l, W_r, W_o, W_v$. As per the matrices, we evaluate the above formula once per column (where a column of $c$ is a single value). The relevant column is a constant value in the constraint checked.
\end{itemize}

A gadget is a series of $a_l, a_r$ (and respective $a_o$) rows, columns in $W_l, W_r, W_o, W_v$, and elements in $c$. They are intended to be reusable snippets we can independently formally verify as correct/create security proofs for.

\newcommand{\al}{\mathsf{a_l.push}}
\newcommand{\ar}{\mathsf{a_r.push}}

\newcommand{\all}{\mathsf{a_l.last()}}
\newcommand{\arl}{\mathsf{a_r.last()}}
\newcommand{\aol}{\mathsf{a_o.last()}}

The following describes each gadget as necessary for human review. Pushes to $\mathsf{a_o}$ are implicit once a push to $\mathsf{a_l}, \mathsf{a_r}$ occurs. $\al(\arl)$ implies a constraint $1 ~\all + -1 ~\arl = 0$.

\subsubsection{Bit}

For $b$, $\al(b), \ar(b - 1)$. We then constrain $1 ~\all + -1 ~\arl = 1$ and $\aol = 0$.

Over a prime field, the multiplication of any two non-zero values will be a non-zero value. Accordingly, one of the values has to be zero for the second constraint to hold true. If the left value, $b$, is zero, $b$ is a valid bit. If the right value is zero, since the right value is constrained to being the left value minus one, the left value must be one (a valid bit).

\subsubsection{Equality}

For $a, b$, we constrain $1 a + -1 b = 0$.

By the simplification $a - b = 0$, and adding $b$ to both sides, we get $a = b$.

\subsubsection{Member of List}

For a claimed member of the list $m$, and the list $l$ (with length $> 0$), we define two distinct set membership gadgets.

When the length of the list $l$ is $1$, list membership is the equality gadget.

Else, $\al(l_0 - m)$. $\ar(l_i - m), \al(\aol) ~\forall~ 1 \le i < \mathsf{len}(l) - 1$. $\ar(l_{\mathsf{len}(l) - 1} - m)$. Constrain $\aol = 0$, and the consistency of all values pushed to $\mathsf{a_l}, \mathsf{a_r}$.

This subtracts the claimed member from each item in the list, multiplying their results. Since, over a prime field, the only way to multiply to zero is to have a factor be zero, the result will only be zero if one of the subtractions resulted in zero. The only way for $a - b = 0$ is if $a = b$.

\subsubsection{Tuple Member of Set}

We create a Pedersen vector commitment for the list and the claimed member. We hash this to obtain weights $w$. Then, for a $n$-length tuple $(a, b, c, ...)$, we perform set membership of $a + w_0 * b + w_1 * c + ...$ over a similarly weighted list.

For this to have an attack in polylogarithmic time, it'd presumably need to be converted to the birthday problem. Since changing the tuple claimed to be a member (the left-hand side) changes the effective list (each member being a potential right-hand side), the two sides aren't independent and Wagner's algorithm isn't usable to find an efficient solution.

\subsubsection{Inverse}

For an element $a$, $\al(a), \ar(a^{-1})$. Constrain $\aol = 1$.

This also works as a proof $a$ is non-zero (as zero will not have a multiplicative inverse).

\subsubsection{On Curve}

For a claimed point $(x, y)$, and the curve formula of the embedded curve $y^2 = x^3 + a x^2 + b x + c$,

\begin{itemize}
	\item $\al(y), \ar(y), 1 ~y_2 + -1 ~\aol = 0$
	\item $\al(x), \ar(x), 1 ~x_2 + -1 ~\aol = 0$
	\item $\al(x), \ar(x), 1 ~y_3 + -1 ~\aol = 0$
	\item $-1 ~y_2 + 1 ~x_3 + a x_2 + b x + c = 0$
\end{itemize}

\subsubsection{Evaluate Divisor}

An elliptic curve divisor is a polynomial modulo the polynomial for the elliptic curve. This means it has $y^2, y, xy^i, x^j$ terms. For an elliptic curve divisor usable within constraints, which requires it present in $a_l, a_r, a_o$, or $V$, we can evaluate it for variables $x, y$. We only discuss the case where $x, y$ are public.

The verifier generates the necessary powers and cross products for $x$ and $y$.

For an example polynomial $a * x^2 + b * x + c$, we rewrite it as $x^2 * a + x * b + c$. With this rearrangement, it's clear how we can use $W_l * a_l + W_r * a_r + W_o * a_o + W_v * V = c$ to evaluate this without extending $a_l, a_r, a_o$. We place the $x, y$ values into $W_*$ and enable obtaining a constraint for the evaluation of the polynomial.

\subsubsection{Discrete Log Proof}

We use elliptic curve divisors, as posited in https://eprint.iacr.org/2022/596.

For a generator $G$, both the prover and the verifier calculate $G_0 = 2^0 \cdot G, ...,G_{254} = 2^{254} \cdot G$. For a scalar for the embedded curve $s$, the prover creates a 255-bit decomposition $b_0, ..., b_{254}$. The prover creates a Pedersen vector commitment for the bits and the divisor interpolating $s \cdot G$ with the relevant powers of $G$.

The verifier hashes this Pedersen vector commitment to a pair of points, $C_0, C_1$. Set $C_2 = -(C_0 + C_1)$. Set $Z$ to the polynomial $y - \lambda x$, and $z$ to $\mu$, where $\lambda, \mu$ are the slope and intercept interpolating the three points.

For each $C_i$,

\begin{enumerate}
	\item The prover evaluates the divisor and runs the inverse gadget on the result. This makes $\all$ the supposed divisor evaluation and $\arl$ the inverse. The former is constrained per 4.3.7.
	\item $\al(\arl)$.
	\item The prover evaluate the divisor differentiated over $x$ and pushes the result to $a_r$. This is constrained per 4.3.7.
	\item $C_{i_{eval_0}} = \aol$
	\item TODO: $dx(A_i) / dz$, $C_{i_{eval_1}} = ~?$
	\item $\al(C_{i_{eval_0}}), \ar(C_{i_{eval_1}})), C_{i_{eval}} = \aol$
\end{enumerate}

We finally constrain $C_{0_{eval}} + C_{1_{eval}} + C_{2_{eval}} - \sum_{i=0}^{254} (1 / (\mu - Z(G_i))) * b_i = 0$.

This proves $b_0, ..., b_{254}$ is the 255-bit decomposition of $s$ where $s$ is the discrete logarithm of $s \cdot G$. It takes 255 in-circuit multiplications to calculate $b_0, ..., b_{254}$ (which are reusable in other discrete log proofs), then 3 in-circuit multiplications are used per $C_i$ (9 in total).

\subsubsection{Discrete Log Proof of Knowledge}

The prior gadgets takes the logarithmic derivative of $D(C_0)D(C_1)D(C_2) = \prod_{i=0}^{254}(\mu - Z(G_i))$ where $D$ is the divisor to enable evaluation with a linear combination (instead of hundreds of in-circuit multiplications).

Eagen's work has an $x$-only divisor equation of $D(C)D(-C) = \prod_{i=0}^{254}(C.x - G_i.x)$. If we instead take the logarithmic derivative of that, the proof loses the ability to differentiate $G_i.x$ from $(-G_i).x$. We can use this to generate a trinary system $-1, 0, 1$ with 161 powers of $G$ ($G, 3 \cdot G, 9 \cdot G$) which generates nearly the same $2^{255}$ group, yet with only 161 trits. Since we cannot distinguish $-1$ form $1$, the prover only has to commit to them as bits, saving 94 in-circuit multiplications. It still satisfies as a proof of knowledge for the discrete log, despite not being binding to the discrete log.

The actual evaluation itself is also cheaper at just 4 in-circuit multiplications due to the single challenge point.

\subsubsection{Incomplete Addition}

For two on-curve points with distinct $x$ coordinates (denoted $(x_0, y_0), (x_1, y_1)$), $x_2, y_2$ can be proved their sum as follows.

The prover provides $\sigma$.

$\al(\sigma), \ar(x_1 - x_0)$

$\aol = y_1 - y_0$

$\al(\sigma), \ar(x_2 - x_0)$

$\aol = -y_2 - y_0$

$\al(\sigma), \ar(\sigma)$

$\aol = x_0 + x_1 + x_2$

\subsubsection{Permissible for Hashing}

In order to not have have to hash points as their $x$ and $y$ coordinates (which would require a tuple set membership invocation and increase the cost of calculating the Pedersen hash), we define an arithmetic hash such that for any $x$ coordinate, only one $y$ coordinate will be accepted. This lets us drop the $y$ coordinate without concern of the prover providing the negative $y$ coordinate (negating the discrete logarithms, enabling double spends).

This cannot be used with linking tag generators, yet can be used for all other points we hash.

For a pair of constants $u, v$, we define $\mathsf{permissible}$ as $\mathsf{sqrt}(u * y + v).\mathsf{is\_some}()$. We consider an $x, y$ permissible if $\mathsf{permissible}(x, y)$ and $!\mathsf{permissible}(x, -y)$. This can be checked in-circuit with just two multiplications, making it incredibly efficient.

Full credit to this idea goes to the authors of Curve Trees, https://eprint.iacr.org/2022/756.

\subsection{Circuit}

We define two distinct layer gadgets, one for the first layer (which ensures the integrity of the tuple output), and one for all additional layers.

\subsubsection{First Layer}

\begin{itemize}
	\item Define $r_o \cdot T, r_c \cdot G, r_j \cdot T$ in-circuit, constrain them on curve, and prove knowledge of the discrete logarithms.
	\item Define $r_i \cdot U$ in-circuit, constrain it on curve, and prove the bit decomposition of $r_i$ the discrete logarithm of $r_i \cdot U$ over $U$.
	\item For the input tuple $\tilde{O}, \tilde{I}, \tilde{C}, R$, prove the $x$-coordinate of $r_o \cdot T$ distinct from the $x$-coordinate of $\tilde{O}$, the $x$-coordinate of $r_i \cdot U$ distinct from the $x$-coordinate of $\tilde{I}$, the $x$-coordinate of $r_c \cdot G$ distinct from the $x$-coordinate of $\tilde{C}$, and the $x$-coordinate of $R$ distinct from the $x$-coordinate of $r_j \cdot T$.
	\item Prove the bit decomposition of $r_i$ (already decomposed and validated as a bitstring) is the discrete logarithm of $R - (r_j \cdot T)$ over $V$.
	\item Perform incomplete addition of $\tilde{O}$ with $-(r_o \cdot T)$ to obtain $O$, $\tilde{I}$ with $-(r_i \cdot U)$ to obtain $I$, and $\tilde{C}$ with $-(r_c \cdot G)$ to obtain $C$.
	\item Prove $O, C$ permissible for hashing.
	\item Perform tuple set membership with $(O.x, I.x, I.y, C.x)$ within a Pedersen vector commitment. This is the hash for the next layer.
\end{itemize}

\subsubsection{Additional Layer}

\begin{itemize}
	\item Define randomness $(r_x, r_y)$ and constrain it's on curve.
	\item Prove knowledge of the discrete logarithm of $(r_x, r_y)$.
	\item Take the blinded Pedersen hash from the prior layer and enforce its $x$ coordinate is inequal to $r_x$. Then perform incomplete addition with $(r_x, -r_y)$.
	
	We do not need to check the blinded Pedersen hash is on-curve in-circuit as we can verify that out of circuit.
	\item With the unblinded Pedersen hash's $x, y$ coordinates, prove it permissible.
	\item Perform set membership of the unblinded Pedersen's hash $x$ coordinate over the members in a Pedersen Vector Commitment (the new blinded Pedersen hash).
\end{itemize}

\newpage

\section{Functionality}

With the system described, it is important to be clear on the functionality in order to fairly evaluate it.

\subsection{Full-Set Privacy}

This is the reason for discussing this in the first place.

\subsection{Hardware Wallets}

Hardware wallets maintain their support due to not needing to perform the membership proof, solely the Generalized Schnorr Protocol after the fact. The Generalized Schnorr Protocol is smaller than the current CLSAG proofs, and is accordingly assumed to be well within the allowed memory footprint. It is only one point larger than the proposed Seraphis ownership proof.

\subsection{Multisig}

Generalized Schnorr Protocols effectively are Schnorr signatures, as the name implies. Accordingly, they benefit from all of the great work performed on Schnorr multisignatures, and can be expected to offer low-complexity, small-constant multisignature protocols.

\subsection{Outgoing View Keys}

Outgoing view keys, a new private key which enables calculating linking tags for scanned outputs without possession of the private key, are inherently enabled by this proposal. Since $x, y$ are needed to spend, yet the linking tag is solely derived from $x$, $x$ becomes the shareable outgoing view key. This does require $y$ be unknown to whoever the outgoing view key is shared to, which is not the case for historical outputs (where $y = 0$).

If wallets publish addresses whose public spend key is not $s \cdot G$ yet $o \cdot G + y \cdot T$, where $y$ is the effective private spend key (uniformly sampled), $o$, the outgoing view key, can be shared. This solely requires wallet software update their key handling internally, and can be done at any moment in time, by any subset of wallets, with no impact to privacy (on- or off-chain) nor network performance.

\subsection{Forward Secrecy}

We define forward secrecy as an adversary with a discrete log oracle being able to, for any output, find a consistent opening for the given input tuple ($\tilde{O}, \tilde{I}, \tilde{C}, R$) and its Spend Authorization + Linkability proof.

Per the following Python script,

https://gist.github.com/kayabaNerve/e09ba62d4a6165ced006b037f1068d95

this is true. The script creates an output, decides all of the necessary nonces, and publishes its solutions. The script proceeds to create a random output (specifically, a random linking tag generator for an output), and from there performs extraction of the various witness values/nonces which would have been used. Since it is able to extract a solution for every variable, and rebuild identical commitments, it is able to forge a indistinguishable proof that output was the output spent. Since any output will have an indistinguishable forged proof, one cannot distinguish a legitimate proof.

An adversary with a discrete log oracle also cannot distinguish between an unspent non-forward-secret output and a forward-secret output. Such an adversary can only calculate what the linking tag would be if the output isn't forward secret, and wait to see if that appears (making it a spent non-forward-secret output).

\subsection{Transaction Chaining}

Since the membership proof does not require knowledge of $x, y$, the membership proof can be produced after the transaction itself is signed. This would let Alice and Bob form a 2-of-2 multisig, sign a transaction spending an output sent to it (per some mutually known blinding factors), then let Alice or Bob create that output, and once it's past the 10-block lock, publish the transaction spending it without the other party's participation.

We do have to ensure the message the Generalized Schnorr Protocol signs isn't binding to the membership proof however.

\newpage

\section{Integration}

With the concepts of the proof established, and the functionality iterated, it's time to discuss how integration will be handled.

\subsection{Tree}

With the circuit proving an output tuple exists within a Merkle tree, we need to create the tree. The tree will be implemented in C++, with the hash function FFI'd from Rust.

The tree is a $l$-layer tree where each layer is of alternative widths $w_a, w_b$. The tree is theoretically considered to be a $\infty$-layer tree, where all members of branches are zero by default. The tree root is the hash within the lowest branch with only one hash.

For the hash function $\mathcal{H}_{tree}$, parameterized by the layer alternation to $\mathcal{H}_{tree_a}, \mathcal{H}_{tree_b}$, and a list of leaves $\mathsf{leaves}$, the tree is calculated as follows:

\begin{enumerate}
	\item $c = a$. Hash $\mathsf{leaves}$ in $w_c$ chunks with $\mathcal{H}_{tree_c}$ to create $\mathsf{leaves.length()} / w_c$ members of the next layer (denoted $\mathsf{members}$).
	\item If $c = a$, $c = b$, else $c = a$. If $\mathsf{members.length()} == 1$, the algorithm terminates. Else, hash $\mathsf{members}$ in $w_c$ chunks with $\mathcal{H}_{tree_c}$ to create $\mathsf{leaves.length()} / w_c$ members of the next layer (which become the new $\mathsf{members}$).
	\item Repeat the prior step.
\end{enumerate}

We expose the following external API, minimizing the intricacies of the tree:

\begin{itemize}
  \item Grow.
  
  Grow incorporates a list of $n$ leaves (themselves tuples $(O, I, C)$) into the tree.
  \item Prune.

  Prune removes a list of $n$ leaves from the tree.
\end{itemize}

With the tree calculation described, and the API defined, we now detail performant implementations of both functions. We take extensive advantage of how the hashes are additively homomorphic ($\mathcal{H}_{tree_c}([A, 0]) + \mathcal{H}_{tree_c}([0, B]) = \mathcal{H}_{tree_c}([A, B])$).

\subsubsection{Grow}

For $\mathsf{outputs}$, a set of output tuples $(O, I, C)$, we separate them as
$$
\mathsf{outputs_0} = \mathsf{outputs[.. ~w_a - (tree.length() \mod w_a)]}
$$
$$
\mathsf{outputs_1} = \mathsf{outputs[(tree.length() \mod w_a) ~..]}
$$

Add $\mathcal{H}_{tree_c}(([0, 0, 0, 0] * (tree.length() \mod w_a)) + \mathsf{outputs_0.flatten()})$ to the most recently appended branch hash for the leaves. The flatten operation transforms $$[(A, B, C), (D, E, F)]$$ to $$[
A.x, B.x, B.y, C.x,
D.x, E.x, E.y, F.x
]$$
(a series of tuples of points to a series of field elements).

Then, for each $w_a$ chunk of $\mathsf{outputs_1}$, hash the flattened chunk, appending the resulting hash to the next layer.

Please note this technically makes the width of the first layer $4 * w_a$, due to considering four field elements (each one word of the hash function) as individual leaves.

For each branch hash modified from $H$ to $H'$, calculate $H'.x - H.x$, the delta. With the proper alignment and chunking, hash the deltas and add the resulting hash to the proper branch hash on the next layer up. Repeat until the only hash modified is the new tree's root.

\subsubsection{Prune}

\begin{enumerate}
  \item For every complete branch of leaves encompassed, remove them.
  \item For every branch of leaves partially modified, hash the removed leaves (properly aligned within the hash function) and subtract them from the existing branch hash if the amount of removed leaves is less than the amount of remaining leaves. If the amount of remaining leaves is less, hash those to re-calculate the hash entirely.
  \item For every hash whose children were modified, perform the above remove/delta-hash procedure until the new tree's root is updated.
\end{enumerate}

\subsection{Permissibility}

For an input tuple $(O, I, C)$, $O, T$ must be permissible before they can be hashed into the tree. $O$ has $T$ added until it's permissible, where for $O = x \cdot G + y \cdot T$, $y$ is incremented as many times as $T$ was added. $C$ has $G$ added until it's permissible, where for $C = r \cdot G + a \cdot H$, $r$ (the commitment mask) is incremented as many times as $G$ was added.

The hash functions, outputting points, are programmed to only output permissible points.

\subsubsection{Initialization}

When an instance of monerod boots with the tree code, it will immediately start indexing every block since genesis. Cryptonote outputs will be accumulated as the key, the linking tag generator, and a Pedersen commitment for the amount (with a randomness of zero). RingCT outputs will be accumulated as the key, the linking tag generator, and their Pedersen commitment.

\subsubsection{Normal Operation}

When a block achieves a depth of 10 (the constant 10 being from the 10-block lock), all outputs within it are used to grow the tree. On a reorganization exceeding 10 blocks, prune is called for the removed outputs. On a reorganization less than 10 blocks which shortens the length of the chain, prune is called for the outputs within blocks no-longer 10-deep.

\subsubsection{Timelocks}

If an output has a block-based timelock, it is set to be accumulated with the outputs of that block. If an output has a time-based timelock prior to the activation of the FCMP++ hard fork, it is converted to an estimated block-based timelock and accumulated with the outputs of that block. After the FCMP++ hard fork, time-based timelocks will be rejected entirely.

Preserving time-based timelocks would require defining a linked list where upon block addition, we check if we should add the output at the head of the list (and any further outputs) to the tree. Unfortunately, such an implementation would be quite easy to perform denial-of-service attacks against. We could also define a vector, enabling efficient insertion, yet then we must define and maintain an unbounded global list which at best can be bucketed (though we'd need to prune from the head of the list, shifting the bucket(s)). With block-based timelocks, we still have the unbounded list commentary, yet have efficient topics (the block number) and no partial list additions. Accordingly, one is not worth the headache, and one has a tolerable headache.

\subsection{Input Modifications}

To minimize modifications to inputs, FCMP++ inputs simply set the amount of key offsets 0.

\subsection{Modifications to RingCT Base}

We define a new RingCT type, $\mathsf{FCMPPlusPlus}$, and with it a new field, $\mathsf{ReferenceBlock}$. $\mathsf{ReferenceBlock}$ is the 32-byte hash of the Monero block which was most recently accumulated into the tree (and therefore must be at least 10 blocks old).

\subsection{Modifications to RingCT Prunable}

We extend prunable with a byte-buffer which is of fixed-length with regards to the amount of outputs. This byte buffer is entirely left to Rust to interpret.

This byte buffer contains $p$ Generalized Schnorr Protocols (which don't sufficiently benefit from being merged into a single proof).

It also contains $n$ Generalized Bulletproofs, which we can structure in two ways.

\begin{itemize}
	\item We can minimize bandwidth by sending one Generalized Bulletproof. This would practically mean limiting the amount of transaction inputs to potentially as low as four.
	
	For context, we limit outputs to sixteen as a transaction with nine outputs has the same amount of computational overhead as a transaction with sixteen outputs. This means for a transaction with nine outputs, we waste seven outputs of computation ($7 * 64$, or $448$, multiplications), For inputs with one Generalized Bulletproof, we'd have the exact same effect, except one input of computation is presumably $3072$ multiplications. This means a single input of wasted computation is as bad as executing Bulletproof range proofs for sixteen outputs, three times over. for no reason at all.
	
	With an input limit of four, the most waste which can occur is one input of work by making a three-input transaction.
	\item We can have no computational overhead by including as many Generalized Bulletproofs as powers of two summed to equal the amount of inputs. For one input, one Generalized Bulletproof. For four inputs, one Generalized Bulletproof. For seven ($4 + 2 + 1$) inputs, three Generalized Bulletproofs. This doesn't waste any performance regarding verification, and roughly makes the expected bandwidth 2.5 kB per two inputs.
\end{itemize}

\subsection{Modifications to Transaction Verification}

$\mathsf{ReferenceBlock}$ is confirmed to be on the best chain and 10-blocks deep. The tree root after applying that block is fetched. The Rust code is called with the tree root, the linking tags, the pseudo-outputs, the byte buffer from RingCT prunable, and the hash of the transaction as used for signing.

As of the most recent hard fork (Bulletproofs+), the only fields from prunable which are hashed when signing are the Bulletproofs. That is maintained. RingCT base is modified to exclude $\mathsf{ReferenceBlock}$ when being serialized for the hash for signing. While this would imply $\mathsf{ReferenceBlock}$ should be placed within prunable, this field cannot be pruned (as it's necessary to evaluate if the transaction should be dropped upon deep reorganization). The lack of hashing it, and malleability regarding the tree used, is explicitly allowed in order to support transaction chaining.

\subsection{Modifications to Addresses}

Addresses do not need modifications. All existing addresses will continue to work as-is. Wallets will work without modifying their keys at all.

\subsubsection{Outgoing View Keys}

In order to take advantage of the outgoing view key functionality, changes to the wallet's internals must be made. This is completely optional to the wallet and can be done at any time without impacting privacy. If it required generating a new address type, that would segment users (impacting privacy), hence the explicit statement there is no impact to privacy.

Wallets would not only generate the new private key, $y$, they would also design and develop a format for sharing $x$, the outgoing view key, and update software to calculate linking tags when scanning outputs if they had the incoming view key and $x$. They would also specify their address with the public spend key $x \cdot G + y \cdot T$, instead of $x \cdot G$. This change is indistinguishable to a recipient of an address and indistinguishable to an adversary with a discrete log oracle.

\subsubsection{Forward Secrecy}

Forward secrecy, if enabled on the protocol level, requires the modifications for outgoing view keys. No additional modifications are required.

\subsection{Modifications to the RPC}

The RPC is extended with a route to return the path for an output (by index) within a specified tree. The existing decoy routes are maintained. A new distribution is added comprehensive to both the Cryptonote outputs and the RingCT outputs.

\subsection{Modifications to Wallets}

Wallets fetch the unified distribution, yet do not fetch the decoy information. Instead, they fetch the path of each selected decoy (and the actual output).

Alternatively, wallets may locally build the tree while scanning the blockchain. This removes the need to request paths for any outputs, as wallets may now locally request the path for their output.

Instead of calling CLSAG's prove with the decoy information, wallets would call the FCMP++ prove with the path of the output being spent. No other changes to wallets are required for full-chain membership proofs (solely for additional, wallet-optional functionality, for which the changes can be done at any time).

\subsection{Multisignature Wallets}

Existing Monero multisignature wallets are still usable. We maintain the DKG process, which effectively creates a n-of-n multisig. We also do not touch wallet scanning/state management, nor utilities (linking proofs).

Multi-party transaction construction isn't modified. The actual signing code is modified. The existing CLSAG code is removed, replaced with either a C++ implementation of multisig OR calls to Rust multisignature code. The latter would involve passing the multisignature wallet key data from C++, re-formatting into a structure the Rust code can work with, and obtaining the preprocesses/signature shares from Rust. The communication and incorporation of those into the signed transaction would occur as prior handled.

\newpage

\section{Future}

Monero can deploy Seraphis, the codebase, in the future. The improvements to transaction construction, and sender-receiver communication (regarding one-time keys and shared secrets), are well-reasoned for Monero and desirable.

Monero can also still deploy Seraphis, the linking tag format, requiring a migration and new addresses. That may offer more efficient membership proofs/a better choice of elliptic curves (better choice throughout the project, not just regarding membership). Generalized Bulletproofs, the gadgets described, and the additional layer circuit section would all be used for a deployment of FCMPs with Seraphis. We'd solely have to simplify the first layer circuit section. The usage of Generalized Schnorr Protocols has also been proposed with Seraphis, which would make an implementation of them from this work potentially reusable.

JAMTIS can also still be deployed (over FCMP++s or over Seraphis).

\end{document}
